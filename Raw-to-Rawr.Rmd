---
title: "MicroWorkshop25"
author: "Adam Oss"
date: "2025-01-25"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## quality checks pre-processed
```{r Raw-to-Rawr#1}

## load libraries
library("dada2")

## link the raw data
path = "./raw/" #set path to raw data

rawF <- sort(list.files(path, pattern="_1.fq.gz", full.names = TRUE, recursive = F)) 
rawR <- sort(list.files(path, pattern="_2.fq.gz", full.names = TRUE, recursive = F))

## get sample names
sample.names <- sapply(strsplit(basename(rawF), "_raw_"), `[`, 1)

## check and plot reads quality
# make folder if doesn't exist
if (!dir.exists(paste0("/reports/"))){ dir.create(paste0("/reports/")) }else{}
# save quality plots as pdf in "./reports" folder
pdf(file = paste0("./reports/","qualityplots_rawdata.pdf")) # saving as pdf
for (i in 1:length(rawF)) { print(dada2::plotQualityProfile(c(rawF[i],rawR[i]), aggregate = F, n = 5000)) }
dev.off() 

```

## Trimming primers
```{r Raw-to-Rawr#2}

## load libraries
library("dada2")
library("ShortRead")
library("magrittr")

## load functions
source("./src/amplicon_functions.R")

## create the output folder for trimmed reads
if (!dir.exists("./trimmed_reads/")){ dir.create("/trimmed_reads/") }else{} 
path_trim = "./trimmed_reads/"

## trimming for Windows

#path to cutadapt windows release
# https://github.com/marcelm/cutadapt/releases
cutapath = "./src/cutadapt.exe" 

## load primers and add reverse complement
primers = Biostrings::readDNAStringSet(filepath = "./primers.fasta")
primers_all = c(primers,Biostrings::complement(primers),Biostrings::reverse(primers), Biostrings::reverseComplement(primers))

#trimming arguments and trimming
for (i in 1:length(rawF)) {
  cutadargs = c("-g",toString(primers_all[1]),
                "-G",toString(primers_all[2]),
                "-a",toString(primers_all[7]),
                "-A",toString(primers_all[8]),
                "-n",1, #for ITS change to 2
                "-o",paste0("./trimmed_reads/", gsub("raw","trim",basename(rawF[i]))),
                "-p",paste0("./trimmed_reads/", gsub("raw","trim",basename(rawR[i]))),
                rawF[i],
                rawR[i],
                "--minimum-length", 30, # minimum length , can be longer
                "--cores",0, #all available cores
                "--report=minimal")
  system2(cutapath, args=cutadargs) } # this line runs it 

trimF <- sort(list.files(path_trim, pattern="trim_1.fq.gz", full.names = TRUE, recursive = F))
trimR <- sort(list.files(path_trim, pattern="trim_2.fq.gz", full.names = TRUE, recursive = F))
```
## quality filtering
```{r Raw-to-Rawr#3}
#paths to filtering output
filtF <- file.path("filtered", paste0(sample.names, "_filt_1.fq.gz")) 
filtR <- file.path("filtered", paste0(sample.names, "_filt_2.fq.gz"))

# filtering and reporting
filtered_report <- dada2::filterAndTrim(fwd = trimF, filt = filtF, 
                                        rev = trimR, filt.rev =  filtR, 
                     minLen = 30, 
                     rm.phix = T,
                     maxN=0,
                     truncQ=2, # optimize this parameter
                     maxEE=c(2,2), # optimize this parameter
                     compress=T, 
                     multithread=T,
                     verbose=T)
 
```

## Learning error rates for novaseq sequencing
```{r Raw-to-Rawr#4}
require("magrittr")
##make sure "magrittr" is loaded
set.seed(33) 

errF <- dada2::learnErrors(filtF,
                    nbases = 1e8,
                    errorEstimationFunction = loessErrfun_mod4,# skip for NOT novaseq
                    randomize = T,
                    MAX_CONSIST = 12,
                    multithread =T,
                    verbose = TRUE)

errR <- dada2::learnErrors(filtR,
                    nbases = 1e8,
                    errorEstimationFunction = loessErrfun_mod4, # skip for NOT novaseq
                    randomize = T,
                    MAX_CONSIST = 12,
                    multithread =F,
                    verbose = TRUE)
# plot error models and save to a file
if (!dir.exists(paste0("./reports/"))){ dir.create(paste0("./reports/")) }else{}
pdf(file = "./reports/dada2_error_plots.pdf")
dada2::plotErrors(errF)
dada2::plotErrors(errR)
dev.off()
##checkpoint1
save.image(file = "rawr_checkpoint.RData")
```
## Dereplication
```{r Raw-to-Rawr#5}
derepF <- dada2::derepFastq(filtF, verbose=T)
names(derepF) <- sample.names
derepR <- dada2::derepFastq(filtR, verbose=T)
names(derepR) <- sample.names
```

## Sample interference
```{r Raw-to-Rawr#6}
dadaF <- dada2::dada(derepF, err=errF, multithread=T, pool=F) # pool sensitivity vs. time
dadaR <- dada2::dada(derepR, err=errR, multithread=T, pool=F)
```

## merging reads
```{r Raw-to-Rawr#7}
mergers <- dada2::mergePairs(dadaF, derepF, dadaR, derepR, minOverlap = 12, verbose=T)
```
## Construct ASV table
```{r Raw-to-Rawr#8}
seqtab <- dada2::makeSequenceTable(mergers)
```
## Chimeras removal
```{r Raw-to-Rawr#9}
seqtab.nochim <- dada2::removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)

##checkpoint2
save.image(file = "rawr_checkpoint.RData")
##
```
## Assign taxonomy
```{r Raw-to-Rawr#10}
# find the database online and download !
taxonomy <- dada2::assignTaxonomy(seqtab.nochim, "./databases/silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE)

# Assignment at species level - not gonna work on laptop
#taxa = dada2::addSpecies(taxa, "../databases/silva_species_assignment_v138.1.fa.gz") 

##checkpoint3
save.image(file = "rawr_checkpoint.RData")
```
## Saving data
```{r Raw-to-Rawr#11}
if (!dir.exists(paste0("./results/"))){ dir.create(paste0("./results/")) }else{}
# Creating sequence reference file and saving it
refseq = NULL
for (i in 1:length(colnames(seqtab.nochim))) {refseq = c(refseq,paste0(">ASV",i),colnames(seqtab.nochim)[i])}
writeLines(refseq,"./results/refseq.fasta")

# Changing sequences in ASV names to ASV[number]
colnames(seqtab.nochim) = paste0(rep("ASV",length(colnames(seqtab.nochim))), 1:length(colnames(seqtab.nochim)))
row.names(taxonomy) = colnames(seqtab.nochim) 

# Save the otu table and taxonomy table
saveRDS(seqtab.nochim, file="./results/otu_table.RDS")
write.csv(seqtab.nochim, file="./results/otu_table.csv", row.names=T)

saveRDS(taxonomy, file="./results/tax_table.RDS")
write.csv(taxonomy, file="./results/tax_table.csv", row.names=T)

```
## post-processing reports
```{r Raw-to-Rawr#12}
if (!dir.exists(paste0("./reports/"))){ dir.create(paste0("./reports/")) }else{}
# Filtering, dechimering
filtered_report = as.data.frame(filtered_report)
filtered_report$survived = round(filtered_report$reads.out / filtered_report$reads.in * 100,2)
filtered_report$seq = rowSums(seqtab)
filtered_report$seq.nochim = rowSums(seqtab.nochim)
filtered_report$seq_pr_rem = round(filtered_report$seq.nochim / filtered_report$seq * 100 , 2)

write.csv2(filtered_report, "./reports/filtered_report.csv" )

# Reads quality - filtered
pdf(file = "./reports/qualityplots_filtered.pdf") # saving as pdf
for (i in 1:length(filtF)) { print(dada2::plotQualityProfile(c(filtF[i],filtR[i]), aggregate = F, n = 5000)) }
dev.off() 

```
